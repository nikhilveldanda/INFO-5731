{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1FUG9lhPBAr"
   },
   "source": [
    "# **The fifth in-class-exercise (40 points in total, 11/11/2021)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWdiEsUqPBAu"
   },
   "source": [
    "(20 points) The purpose of the question is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
    "\n",
    "The dataset can be download from here: https://github.com/unt-iialab/info5731_spring2021/blob/main/class_exercises/exercise09_datacollection.zip. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
    "\n",
    "Algorithms:\n",
    "\n",
    "(1) MultinominalNB\n",
    "\n",
    "(2) SVM \n",
    "\n",
    "(3) KNN \n",
    "\n",
    "(4) Decision tree\n",
    "\n",
    "(5) Random Forest\n",
    "\n",
    "(6) XGBoost\n",
    "\n",
    "Evaluation measurement:\n",
    "\n",
    "(1) Accuracy\n",
    "\n",
    "(2) Recall\n",
    "\n",
    "(3) Precison \n",
    "\n",
    "(4) F-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "B2J_4kSUrkki"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = open('stsa-train.txt').read()\n",
    "labels, text = [], []\n",
    "for i, line in enumerate(data.split(\"\\n\")):\n",
    "    content = line.split(' ')\n",
    "    labels.append(content[0])\n",
    "    text.append(\" \".join(content[1:]))\n",
    "testing_data = open('stsa-test.txt').read()\n",
    "test_labels, test_text = [], []\n",
    "for i, line in enumerate(testing_data.split(\"\\n\")):\n",
    "    content = line.split(' ')\n",
    "    test_labels.append(content[0])\n",
    "    test_text.append(\" \".join(content[1:]))\n",
    "\n",
    "\n",
    "df = pd.DataFrame (list(zip(text, labels)) , columns = ['Raw Text', 'Labels'])\n",
    "test_df = pd.DataFrame (list(zip(test_text, test_labels)) , columns = ['Raw Text', 'Labels'])\n",
    "test_df = test_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cug_1wiOryqc",
    "outputId": "e2aa02bc-7ebd-49b5-eb79-2cc57dcbfb51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Downloader\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> d\n",
      "\n",
      "Download which package (l=list; x=cancel)?\n",
      "  Identifier> all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Downloading collection 'all'\n",
      "       | \n",
      "       | Downloading package abc to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/abc.zip.\n",
      "       | Downloading package alpino to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/alpino.zip.\n",
      "       | Downloading package biocreative_ppi to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/biocreative_ppi.zip.\n",
      "       | Downloading package brown to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/brown.zip.\n",
      "       | Downloading package brown_tei to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/brown_tei.zip.\n",
      "       | Downloading package cess_cat to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/cess_cat.zip.\n",
      "       | Downloading package cess_esp to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/cess_esp.zip.\n",
      "       | Downloading package chat80 to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/chat80.zip.\n",
      "       | Downloading package city_database to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/city_database.zip.\n",
      "       | Downloading package cmudict to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/cmudict.zip.\n",
      "       | Downloading package comparative_sentences to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/comparative_sentences.zip.\n",
      "       | Downloading package comtrans to /home/jovyan/nltk_data...\n",
      "       | Downloading package conll2000 to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/conll2000.zip.\n",
      "       | Downloading package conll2002 to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/conll2002.zip.\n",
      "       | Downloading package conll2007 to /home/jovyan/nltk_data...\n",
      "       | Downloading package crubadan to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/crubadan.zip.\n",
      "       | Downloading package dependency_treebank to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/dependency_treebank.zip.\n",
      "       | Downloading package dolch to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/dolch.zip.\n",
      "       | Downloading package europarl_raw to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/europarl_raw.zip.\n",
      "       | Downloading package floresta to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/floresta.zip.\n",
      "       | Downloading package framenet_v15 to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/framenet_v15.zip.\n",
      "       | Downloading package framenet_v17 to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/framenet_v17.zip.\n",
      "       | Downloading package gazetteers to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/gazetteers.zip.\n",
      "       | Downloading package genesis to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/genesis.zip.\n",
      "       | Downloading package gutenberg to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/gutenberg.zip.\n",
      "       | Downloading package ieer to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/ieer.zip.\n",
      "       | Downloading package inaugural to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/inaugural.zip.\n",
      "       | Downloading package indian to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/indian.zip.\n",
      "       | Downloading package jeita to /home/jovyan/nltk_data...\n",
      "       | Downloading package kimmo to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/kimmo.zip.\n",
      "       | Downloading package knbc to /home/jovyan/nltk_data...\n",
      "       | Downloading package lin_thesaurus to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/lin_thesaurus.zip.\n",
      "       | Downloading package mac_morpho to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/mac_morpho.zip.\n",
      "       | Downloading package machado to /home/jovyan/nltk_data...\n",
      "       | Downloading package masc_tagged to /home/jovyan/nltk_data...\n",
      "       | Downloading package moses_sample to /home/jovyan/nltk_data...\n",
      "       |   Unzipping models/moses_sample.zip.\n",
      "       | Downloading package movie_reviews to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/movie_reviews.zip.\n",
      "       | Downloading package names to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/names.zip.\n",
      "       | Downloading package nombank.1.0 to /home/jovyan/nltk_data...\n",
      "       | Downloading package nps_chat to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/nps_chat.zip.\n",
      "       | Downloading package omw to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/omw.zip.\n",
      "       | Downloading package opinion_lexicon to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/opinion_lexicon.zip.\n",
      "       | Downloading package paradigms to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/paradigms.zip.\n",
      "       | Downloading package pil to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/pil.zip.\n",
      "       | Downloading package pl196x to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/pl196x.zip.\n",
      "       | Downloading package ppattach to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/ppattach.zip.\n",
      "       | Downloading package problem_reports to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/problem_reports.zip.\n",
      "       | Downloading package propbank to /home/jovyan/nltk_data...\n",
      "       | Downloading package ptb to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/ptb.zip.\n",
      "       | Downloading package product_reviews_1 to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/product_reviews_1.zip.\n",
      "       | Downloading package product_reviews_2 to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/product_reviews_2.zip.\n",
      "       | Downloading package pros_cons to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/pros_cons.zip.\n",
      "       | Downloading package qc to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/qc.zip.\n",
      "       | Downloading package reuters to /home/jovyan/nltk_data...\n",
      "       | Downloading package rte to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/rte.zip.\n",
      "       | Downloading package semcor to /home/jovyan/nltk_data...\n",
      "       | Downloading package senseval to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/senseval.zip.\n",
      "       | Downloading package sentiwordnet to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/sentiwordnet.zip.\n",
      "       | Downloading package sentence_polarity to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/sentence_polarity.zip.\n",
      "       | Downloading package shakespeare to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/shakespeare.zip.\n",
      "       | Downloading package sinica_treebank to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/sinica_treebank.zip.\n",
      "       | Downloading package smultron to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/smultron.zip.\n",
      "       | Downloading package state_union to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/state_union.zip.\n",
      "       | Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/stopwords.zip.\n",
      "       | Downloading package subjectivity to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/subjectivity.zip.\n",
      "       | Downloading package swadesh to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/swadesh.zip.\n",
      "       | Downloading package switchboard to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/switchboard.zip.\n",
      "       | Downloading package timit to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/timit.zip.\n",
      "       | Downloading package toolbox to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/toolbox.zip.\n",
      "       | Downloading package treebank to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/treebank.zip.\n",
      "       | Downloading package twitter_samples to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/twitter_samples.zip.\n",
      "       | Downloading package udhr to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/udhr.zip.\n",
      "       | Downloading package udhr2 to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/udhr2.zip.\n",
      "       | Downloading package unicode_samples to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/unicode_samples.zip.\n",
      "       | Downloading package universal_treebanks_v20 to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       | Downloading package verbnet to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/verbnet.zip.\n",
      "       | Downloading package verbnet3 to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/verbnet3.zip.\n",
      "       | Downloading package webtext to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/webtext.zip.\n",
      "       | Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "       |   Package wordnet is already up-to-date!\n",
      "       | Downloading package wordnet31 to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/wordnet31.zip.\n",
      "       | Downloading package wordnet_ic to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/wordnet_ic.zip.\n",
      "       | Downloading package words to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/words.zip.\n",
      "       | Downloading package ycoe to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/ycoe.zip.\n",
      "       | Downloading package rslp to /home/jovyan/nltk_data...\n",
      "       |   Unzipping stemmers/rslp.zip.\n",
      "       | Downloading package maxent_treebank_pos_tagger to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "       | Downloading package universal_tagset to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping taggers/universal_tagset.zip.\n",
      "       | Downloading package maxent_ne_chunker to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "       | Downloading package punkt to /home/jovyan/nltk_data...\n",
      "       |   Unzipping tokenizers/punkt.zip.\n",
      "       | Downloading package book_grammars to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping grammars/book_grammars.zip.\n",
      "       | Downloading package sample_grammars to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping grammars/sample_grammars.zip.\n",
      "       | Downloading package spanish_grammars to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping grammars/spanish_grammars.zip.\n",
      "       | Downloading package basque_grammars to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping grammars/basque_grammars.zip.\n",
      "       | Downloading package large_grammars to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping grammars/large_grammars.zip.\n",
      "       | Downloading package tagsets to /home/jovyan/nltk_data...\n",
      "       |   Unzipping help/tagsets.zip.\n",
      "       | Downloading package snowball_data to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       | Downloading package bllip_wsj_no_aux to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping models/bllip_wsj_no_aux.zip.\n",
      "       | Downloading package word2vec_sample to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping models/word2vec_sample.zip.\n",
      "       | Downloading package panlex_swadesh to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       | Downloading package mte_teip5 to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/mte_teip5.zip.\n",
      "       | Downloading package averaged_perceptron_tagger to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "       | Downloading package averaged_perceptron_tagger_ru to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping taggers/averaged_perceptron_tagger_ru.zip.\n",
      "       | Downloading package perluniprops to /home/jovyan/nltk_data...\n",
      "       |   Unzipping misc/perluniprops.zip.\n",
      "       | Downloading package nonbreaking_prefixes to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
      "       | Downloading package vader_lexicon to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       | Downloading package porter_test to /home/jovyan/nltk_data...\n",
      "       |   Unzipping stemmers/porter_test.zip.\n",
      "       | Downloading package wmt15_eval to /home/jovyan/nltk_data...\n",
      "       |   Unzipping models/wmt15_eval.zip.\n",
      "       | Downloading package mwa_ppdb to /home/jovyan/nltk_data...\n",
      "       |   Unzipping misc/mwa_ppdb.zip.\n",
      "       | \n",
      "     Done downloading collection all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> q\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "df-abo0iru-4",
    "outputId": "1aeaa58d-32cc-4eb9-c8d3-80589533bd98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/tmp/ipykernel_41/405654497.py:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Removal of Punctuation'] = df['Lower Case'].str.replace('[^\\w\\s]','')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from nltk.stem import PorterStemmer\n",
    "from textblob import Word\n",
    "nltk.download('wordnet')\n",
    "st = PorterStemmer()\n",
    "nltk.download('punkt')\n",
    "stop = stopwords.words('english')\n",
    "df['Lower Case'] = df['Raw Text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "df['Removal of Punctuation'] = df['Lower Case'].str.replace('[^\\w\\s]','')\n",
    "df['Removal of Special Characters'] = df['Removal of Punctuation'].apply(lambda x: ''.join(re.sub(r\"[^a-zA-Z0-9]+\", ' ', charctr) for charctr in x ))\n",
    "df['Stopwords Removal'] = df['Removal of Punctuation'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "df['Tokenization'] = df['Stopwords Removal'].apply(lambda x: TextBlob(x).words)\n",
    "df['After Lemmatization'] = df['Tokenization'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BL19N3lIsOps"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41/2737988582.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_df['Removal of Punctuation'] = test_df['Lower Case'].str.replace('[^\\w\\s]','')\n"
     ]
    }
   ],
   "source": [
    "test_df['Lower Case'] = test_df['Raw Text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "test_df['Removal of Punctuation'] = test_df['Lower Case'].str.replace('[^\\w\\s]','')\n",
    "test_df['Removal of Special Characters'] = test_df['Removal of Punctuation'].apply(lambda x: ''.join(re.sub(r\"[^a-zA-Z0-9]+\", ' ', charctr) for charctr in x ))\n",
    "test_df['Stopwords Removal'] = test_df['Removal of Punctuation'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "test_df['Tokenization'] = test_df['Stopwords Removal'].apply(lambda x: TextBlob(x).words)\n",
    "test_df['After Lemmatization'] = test_df['Tokenization'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TG7A03A7sOzK"
   },
   "outputs": [],
   "source": [
    "# Data Transformations\n",
    "from sklearn import model_selection, preprocessing, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word')\n",
    "tfidf_vect.fit(df['After Lemmatization'])\n",
    "x_tfidf =  tfidf_vect.transform(df['After Lemmatization'])\n",
    "vect_test = TfidfVectorizer(analyzer='word', vocabulary = tfidf_vect.vocabulary_)\n",
    "vect_test.fit(test_df['After Lemmatization'])\n",
    "xtest = vect_test.transform(test_df['After Lemmatization'])\n",
    "test_y = test_df['Labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IIY2RZa_sO3Y"
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, naive_bayes, metrics, svm\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(x_tfidf, df['Labels'].values,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "WoGIz9DVs1mW"
   },
   "outputs": [],
   "source": [
    "def get_metrics(predictions, test_data_y):\n",
    "  accuracy = metrics.accuracy_score(predictions, test_data_y)\n",
    "  precision = metrics.precision_score(predictions, test_data_y, pos_label='positive', average='micro')\n",
    "  recall = metrics.recall_score(predictions, test_data_y, pos_label='positive', average='micro')\n",
    "  f1 = metrics.f1_score(predictions, test_data_y, pos_label='positive', average='micro')\n",
    "  return accuracy, precision, recall, f1\n",
    "def cross_validation_score(modelName, x, y):\n",
    "  scoring = 'accuracy'\n",
    "  kfold = KFold(10, random_state = 7,shuffle=True)\n",
    "  cross_val = cross_val_score(modelName, x, y, cv=kfold).mean()\n",
    "  return cross_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cBj4XlA-s1pM",
    "outputId": "a93e536e-374a-49c5-f601-d89e74a91c17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7776173285198555\n",
      "Precision is 0.7776173285198555\n",
      "Recall is 0.7776173285198555\n",
      "F1 is 0.7776173285198555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    }
   ],
   "source": [
    "# Navie Bayes\n",
    "naive_bayes_model = naive_bayes.MultinomialNB()\n",
    "naive_bayes_model.fit(train_x, train_y)\n",
    "naive_bayes_predictions_validation_data = naive_bayes_model.predict(valid_x)\n",
    "accuracy, precision, recall, f1 = get_metrics(naive_bayes_predictions_validation_data, valid_y)\n",
    "print(\"Accuracy is {0}\\nPrecision is {1}\\nRecall is {2}\\nF1 is {3}\".format(accuracy, precision, recall, f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yaLBpnNytN4l",
    "outputId": "98836add-289b-42e8-d702-4696f060f9f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navie Bayes Cross Validation Score is 0.71049942654572\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Score\n",
    "nb_scores_mean = cross_validation_score(naive_bayes_model, valid_x, valid_y)\n",
    "print('Navie Bayes Cross Validation Score is {0}'.format(nb_scores_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AsYsb2VgtN7I",
    "outputId": "734deb91-93d3-4bd9-8163-0112de7a8917"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7941822173435785\n",
      "Precision is 0.7941822173435785\n",
      "Recall is 0.7941822173435785\n",
      "F1 is 0.7941822173435786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    }
   ],
   "source": [
    "# Testing metrics\n",
    "naive_bayes_predictions_test_data = naive_bayes_model.predict(xtest)\n",
    "accuracy, precision, recall, f1 = get_metrics(naive_bayes_predictions_test_data, test_y)\n",
    "print(\"Accuracy is {0}\\nPrecision is {1}\\nRecall is {2}\\nF1 is {3}\".format(accuracy, precision, recall, f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1h_ekeQtN9_",
    "outputId": "90891447-0cb1-480f-f942-d5cb09a1d996"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navie Bayes Cross Validation Score is 0.7371044256290158\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Score - Testing\n",
    "nb_test_scores_mean = cross_validation_score(naive_bayes_model, xtest, test_y)\n",
    "print('Navie Bayes Cross Validation Score is {0}'.format(nb_test_scores_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1gHHECPAtOBJ"
   },
   "outputs": [],
   "source": [
    "# SVM - Validation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0-eAYQ7tODm",
    "outputId": "18cfeb25-3896-457b-932c-8d2de3154a84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.768231046931408\n",
      "Precision is 0.768231046931408\n",
      "Recall is 0.768231046931408\n",
      "F1 is 0.768231046931408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    }
   ],
   "source": [
    "svm_model = svm.SVC()\n",
    "svm_model.fit(train_x, train_y)\n",
    "svm_predictions_validation_data = svm_model.predict(valid_x)\n",
    "accuracy, precision, recall, f1 = get_metrics(svm_predictions_validation_data, valid_y)\n",
    "print(\"Accuracy is {0}\\nPrecision is {1}\\nRecall is {2}\\nF1 is {3}\".format(accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Of5DirHbtOG6",
    "outputId": "1b9e54c8-3e05-41b6-e1e5-683a3d6720fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Cross Validation Score is 0.7061411740173079\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Score\n",
    "svm_scores_mean = cross_validation_score(svm_model, valid_x, valid_y)\n",
    "print('SVM Cross Validation Score is {0}'.format(svm_scores_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l_0NL2hKs1ry",
    "outputId": "2fcfe20b-965d-4844-f043-afbfda0e7905"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7810098792535675\n",
      "Precision is 0.7810098792535675\n",
      "Recall is 0.7810098792535675\n",
      "F1 is 0.7810098792535675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    }
   ],
   "source": [
    "# Testing Metrics\n",
    "svm_predictions_test_data = svm_model.predict(xtest)\n",
    "accuracy, precision, recall, f1 = get_metrics(svm_predictions_test_data, test_y)\n",
    "print(\"Accuracy is {0}\\nPrecision is {1}\\nRecall is {2}\\nF1 is {3}\".format(accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "djvm7O4ls1vP",
    "outputId": "0fc4e504-c22f-4feb-9028-32416d91ffd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Cross Validation Score is 0.7239086050561461\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Score - Testing\n",
    "svm_test_scores_mean = cross_validation_score(svm_model, xtest, test_y)\n",
    "print('SVM Cross Validation Score is {0}'.format(svm_test_scores_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K9PKg5oluHow",
    "outputId": "c07b261c-da45-47be-f40f-593aa5e198a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7292418772563177\n",
      "Precision is 0.7292418772563177\n",
      "Recall is 0.7292418772563177\n",
      "F1 is 0.7292418772563178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    }
   ],
   "source": [
    "# KNN - Validation Metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model = KNeighborsClassifier(n_neighbors = 15)\n",
    "knn_model.fit(train_x, train_y)\n",
    "knn_predictions_valid_data = knn_model.predict(valid_x)\n",
    "accuracy, precision, recall, f1 = get_metrics(knn_predictions_valid_data, valid_y)\n",
    "print(\"Accuracy is {0}\\nPrecision is {1}\\nRecall is {2}\\nF1 is {3}\".format(accuracy, precision, recall, f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mhl2qE02uHrr",
    "outputId": "6e5b1db3-4980-457c-90b4-bb01a28fd6d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Cross Validation Score is 0.6779637159837347\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Score\n",
    "knn_scores_mean = cross_validation_score(knn_model, valid_x, valid_y)\n",
    "print('KNN Cross Validation Score is {0}'.format(knn_scores_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OW9uwjE6uHuZ",
    "outputId": "6d2eaf80-dfa0-4871-8c1e-b658e2fe64a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7316136114160263\n",
      "Precision is 0.7316136114160263\n",
      "Recall is 0.7316136114160263\n",
      "F1 is 0.7316136114160263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    }
   ],
   "source": [
    "# Testing Metrics\n",
    "knn_predictions_test_data = knn_model.predict(xtest)\n",
    "accuracy, precision, recall, f1 = get_metrics(knn_predictions_test_data, test_y)\n",
    "print(\"Accuracy is {0}\\nPrecision is {1}\\nRecall is {2}\\nF1 is {3}\".format(accuracy, precision, recall, f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eOt1M_PQuHxh",
    "outputId": "fa0a2c3a-007c-4cb6-8d7a-bc97ff1afe0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Cross Validation Score is 0.6361376328589443\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Score - Testing\n",
    "knn_test_scores_mean = cross_validation_score(knn_model, xtest, test_y)\n",
    "print('KNN Cross Validation Score is {0}'.format(knn_test_scores_mean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uS6WatWUuHzy",
    "outputId": "d3be80c1-91c3-4740-c24c-3b6fd332899c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.6389891696750902\n",
      "Precision is 0.6389891696750902\n",
      "Recall is 0.6389891696750902\n",
      "F1 is 0.6389891696750902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree - Validation Metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(train_x, train_y)\n",
    "dt_predictions_valid_data = dt_model.predict(valid_x)\n",
    "accuracy, precision, recall, f1 = get_metrics(dt_predictions_valid_data, valid_y)\n",
    "print(\"Accuracy is {0}\\nPrecision is {1}\\nRecall is {2}\\nF1 is {3}\".format(accuracy, precision, recall, f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L5j_x0Z7uH3E",
    "outputId": "c2f3b4ed-029f-4237-9d94-6009872abac9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Cross Validation Score is 0.5848295276822021\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Score\n",
    "dt_scores_mean = cross_validation_score(dt_model, valid_x, valid_y)\n",
    "print('Decision Tree Cross Validation Score is {0}'.format(dt_scores_mean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZN852JP8uH7Y",
    "outputId": "62bbccc1-2b95-4b19-cd8a-dd18b46afc64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.6476399560922064\n",
      "Precision is 0.6476399560922064\n",
      "Recall is 0.6476399560922064\n",
      "F1 is 0.6476399560922064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    }
   ],
   "source": [
    "# Testing Metrics\n",
    "dt_predictions_test_data = dt_model.predict(xtest)\n",
    "accuracy, precision, recall, f1 = get_metrics(dt_predictions_test_data, test_y)\n",
    "print(\"Accuracy is {0}\\nPrecision is {1}\\nRecall is {2}\\nF1 is {3}\".format(accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KYfiudB5uH9X",
    "outputId": "1b94c12c-2c94-4f97-e827-716cd98b2c18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Cross Validation Score is 0.6212514261694588\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Score - Testing\n",
    "dt_test_scores_mean = cross_validation_score(dt_model, xtest, test_y)\n",
    "print('Decision Tree Cross Validation Score is {0}'.format(dt_test_scores_mean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L3vUH-SfuvG6",
    "outputId": "d676c0d1-2601-48eb-e19c-94c2536e2d3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.71985559566787\n",
      "Precision is 0.71985559566787\n",
      "Recall is 0.71985559566787\n",
      "F1 is 0.71985559566787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    }
   ],
   "source": [
    "# Random Forest - Validation Metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(train_x, train_y)\n",
    "rf_predictions_valid_data = rf_model.predict(valid_x)\n",
    "accuracy, precision, recall, f1 = get_metrics(rf_predictions_valid_data, valid_y)\n",
    "print(\"Accuracy is {0}\\nPrecision is {1}\\nRecall is {2}\\nF1 is {3}\".format(accuracy, precision, recall, f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s5URh7u7uvJ5",
    "outputId": "a1213501-c3bb-40ff-ac5f-55085a60c620"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Cross Validation Score is 0.6310499426545719\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Score\n",
    "rf_scores_mean = cross_validation_score(rf_model, valid_x, valid_y)\n",
    "print('Random Forest Cross Validation Score is {0}'.format(rf_scores_mean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_wLDFqVfuvMk",
    "outputId": "8b09ca16-2026-486e-c055-b4b352011728"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7327113062568605\n",
      "Precision is 0.7327113062568605\n",
      "Recall is 0.7327113062568605\n",
      "F1 is 0.7327113062568605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    }
   ],
   "source": [
    "# Testing Metrics\n",
    "rf_predictions_test_data = rf_model.predict(xtest)\n",
    "accuracy, precision, recall, f1 = get_metrics(rf_predictions_test_data, test_y)\n",
    "print(\"Accuracy is {0}\\nPrecision is {1}\\nRecall is {2}\\nF1 is {3}\".format(accuracy, precision, recall, f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NHK8G3oXuvPh",
    "outputId": "c6f4254d-87b1-4388-8324-5991f733ba3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Cross Validation Score is 0.6635471086290758\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Score - Testing\n",
    "rf_test_scores_mean = cross_validation_score(rf_model, xtest, test_y)\n",
    "print('Random Forest Cross Validation Score is {0}'.format(rf_test_scores_mean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.5.0-py3-none-manylinux2014_x86_64.whl (173.5 MB)\n",
      "\u001b[K     || 173.5 MB 285 kB/s  eta 0:00:01  |                               | 3.5 MB 7.4 MB/s eta 0:00:23     |                           | 26.7 MB 18.6 MB/s eta 0:00:08     |                      | 53.5 MB 14.0 MB/s eta 0:00:09     |                 | 81.6 MB 17.3 MB/s eta 0:00:06     |                | 82.6 MB 17.3 MB/s eta 0:00:06     |         | 123.3 MB 19.8 MB/s eta 0:00:03     || 172.5 MB 19.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from xgboost) (1.21.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from xgboost) (1.7.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KQ7DQGpWuvSX",
    "outputId": "75ff2273-bb3b-4547-9c11-474c64433284"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:45:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy is 0.688086642599278\n",
      "Precision is 0.688086642599278\n",
      "Recall is 0.688086642599278\n",
      "F1 is 0.688086642599278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    }
   ],
   "source": [
    "# XG Boost - Validation Metrics\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "xg_model = XGBClassifier()\n",
    "xg_model.fit(train_x, train_y)\n",
    "xg_predictions_valid_data = xg_model.predict(valid_x)\n",
    "accuracy, precision, recall, f1 = get_metrics(xg_predictions_valid_data, valid_y)\n",
    "print(\"Accuracy is {0}\\nPrecision is {1}\\nRecall is {2}\\nF1 is {3}\".format(accuracy, precision, recall, f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "henCwFAluvWH",
    "outputId": "6870aec0-414c-4e92-a153-23c09d6a147b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:46:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:46:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:46:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:46:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:46:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:46:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:46:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:46:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:46:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:46:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XG Boost Cross Validation Score is 0.6080022938171202\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Score\n",
    "xg_scores_mean = cross_validation_score(XGBClassifier(), valid_x, valid_y)\n",
    "print('XG Boost Cross Validation Score is {0}'.format(xg_scores_mean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hRBGJYuKPBAv",
    "outputId": "4c989341-05ff-4534-f9bb-451ddae62a05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.6849615806805708\n",
      "Precision is 0.6849615806805708\n",
      "Recall is 0.6849615806805708\n",
      "F1 is 0.6849615806805708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    }
   ],
   "source": [
    "# Testing Metrics\n",
    "xg_predictions_test_data = xg_model.predict(xtest)\n",
    "accuracy, precision, recall, f1 = get_metrics(xg_predictions_test_data, test_y)\n",
    "print(\"Accuracy is {0}\\nPrecision is {1}\\nRecall is {2}\\nF1 is {3}\".format(accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MfjFH14QvUp7",
    "outputId": "e20e3c97-2543-44e6-fcf3-314f782cd6ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:46:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:46:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:46:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:46:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:46:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:46:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:46:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:46:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:46:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:46:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XG Boost Cross Validation Score is 0.6454392601933584\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Score - Testing\n",
    "xg_test_scores_mean = cross_validation_score(XGBClassifier(), xtest, test_y)\n",
    "print('XG Boost Cross Validation Score is {0}'.format(xg_test_scores_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRV48PUZvfCj"
   },
   "source": [
    "Accuracies of the models are as follows when use test data -\n",
    "\n",
    "Navie Bayes - 78.14%\n",
    "\n",
    "SVM - 78.30%\n",
    "\n",
    "KNN - 72.92%\n",
    "\n",
    "Decision Tree - 67.14%\n",
    "\n",
    "Random Forest - 73.14%\n",
    "\n",
    "XG Boost - 62.92%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMKsZmoDPBAw"
   },
   "source": [
    "(20 points) The purpose of the question is to practice different machine learning algorithms for text clustering\n",
    "Please downlad the dataset by using the following link.  https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones\n",
    "(You can also use different text data which you want)\n",
    "\n",
    "Apply the listed clustering methods to the dataset:\n",
    "\n",
    "K means, \n",
    "DBSCAN,\n",
    "Hierarchical clustering. \n",
    "\n",
    "You can refer to of the codes from  the follwing link below. \n",
    "https://www.kaggle.com/karthik3890/text-clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "w26LQkvKPBAx"
   },
   "outputs": [],
   "source": [
    "#Write your code here.\n",
    "import pandas as pd\n",
    "Cluster_Data = pd.read_csv(\"Amazon_Unlocked_Mobile.csv\",nrows=30000)\n",
    "\n",
    "Cluster_Data.dropna(inplace=True)\n",
    "Cluster_Data.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22340, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cluster_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Aj1Lb-kuLUi8",
    "outputId": "99f98e00-3d65-4803-d8d4-056e67f83997"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Product Name', 'Brand Name', 'Price', 'Rating', 'Reviews',\n",
       "       'Review Votes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('all')\n",
    "Cluster_Data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "rxOu4usDMnl4"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "from nltk.corpus import stopwords\n",
    "def remove_stopword(word):\n",
    "    return word not in words\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "Lemma = WordNetLemmatizer()\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "Cluster_Data['NewReviews'] = Cluster_Data['Reviews'].str.lower().str.split()\n",
    "Cluster_Data['NewReviews'] = Cluster_Data['NewReviews'].apply(lambda x : [item for item in x if item not in stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "k5T9R7ZDMt3O"
   },
   "outputs": [],
   "source": [
    "Cluster_Data['Cleaned_reviews'] = [''.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line))\n",
    "for line in lists]).strip() for lists in Cluster_Data['NewReviews']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22340, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cluster_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Product Name', 'Brand Name', 'Price', 'Rating', 'Reviews',\n",
       "       'Review Votes', 'NewReviews', 'Cleaned_reviews'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cluster_Data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "U2BXynf4MyV6"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.5,max_features=10000,min_df=10,stop_words='english',use_idf=True)\n",
    "# Cluster_Data[\"Vectors\"] = vectorizer.fit_transform(Cluster_Data['Cleaned_reviews'].str.upper())\n",
    "X = vectorizer.fit_transform(Cluster_Data['Cleaned_reviews'].str.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kGbpt_v7M5-y",
    "outputId": "047648d1-7b44-4c03-8dec-d2cf8df80f4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 0: mobile fine cost happyphone far unlocked phone times bought good\n",
      "cluster 1: good greatphone great excellent loveit perfect thankyou lovephone love phone\n",
      "cluster 2: nice thanks phonedescribed boughtphone new price perfectcondition workwell likenew yes\n",
      "cluster 3: iphone gs new loveit plus faster gbphone storage cost unlocked\n",
      "cluster 4: workgreat thanks loveit fastshipping lovephone workgood greatphone goodcondition cametime productdescribed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "km = KMeans(n_clusters=5,init='k-means++',max_iter=200,n_init=1)\n",
    "km.fit(X)\n",
    "terms = vectorizer.get_feature_names()\n",
    "order_centroids = km.cluster_centers_.argsort()[:,::-1]\n",
    "for i in range(5):\n",
    "    print(\"cluster %d:\" %i,end='')\n",
    "    for ind in order_centroids[i,:10]:\n",
    "        print(' %s' % terms[ind],end='')\n",
    "    print()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    21261\n",
       "4      532\n",
       "3      316\n",
       "2      127\n",
       "0      104\n",
       "Name: KMEANS, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cluster_Data[\"KMEANS\"] = km.labels_\n",
    "Cluster_Data[\"KMEANS\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "zdftUm83OMKd"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "E2aeV0eYOU2x"
   },
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.123, min_samples = 2)\n",
    "clusters = dbscan.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0       10139\n",
       "-1        1142\n",
       " 8         581\n",
       " 31        267\n",
       " 30        241\n",
       "         ...  \n",
       " 1041        2\n",
       " 1042        2\n",
       " 1043        2\n",
       " 1044        2\n",
       " 582         2\n",
       "Name: DBSCAN, Length: 1509, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cluster_Data[\"DBSCAN\"] = dbscan.labels_\n",
    "Cluster_Data[\"DBSCAN\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgglomerativeClustering(n_clusters=5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "model = AgglomerativeClustering(n_clusters=5, affinity='euclidean')\n",
    "model.fit(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    21016\n",
       "3      582\n",
       "2      267\n",
       "4      243\n",
       "1      232\n",
       "Name: Hierarchical clustering, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cluster_Data[\"Hierarchical clustering\"] = model.labels_\n",
    "Cluster_Data[\"Hierarchical clustering\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "      <th>NewReviews</th>\n",
       "      <th>Cleaned_reviews</th>\n",
       "      <th>KMEANS</th>\n",
       "      <th>DBSCAN</th>\n",
       "      <th>Hierarchical clustering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[feel, lucky, found, used, (phone, us, &amp;, used...</td>\n",
       "      <td>feelluckyfoundused phoneu usedhardall  phoneli...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[nice, phone,, nice, grade, pantach, revue., c...</td>\n",
       "      <td>nicephone nicegradepantachrevue cleanseteasyse...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Very pleased</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[pleased]</td>\n",
       "      <td>pleased</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>It works good but it goes slow sometimes but i...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[works, good, goes, slow, sometimes, good, pho...</td>\n",
       "      <td>workgoodgoslowsometimesgoodphonelove</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>Great phone to replace my lost phone. The only...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[great, phone, replace, lost, phone., thing, v...</td>\n",
       "      <td>greatphonereplacelostphone thingvolumebuttonwo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22335</th>\n",
       "      <td>29995</td>\n",
       "      <td>Apple iPhone 5c 32GB (Blue) - AT&amp;T</td>\n",
       "      <td>Apple</td>\n",
       "      <td>274.95</td>\n",
       "      <td>5</td>\n",
       "      <td>The description said it was in 'very good' con...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[description, said, 'very, good', condition,, ...</td>\n",
       "      <td>descriptionsaid verygood condition actuallyrec...</td>\n",
       "      <td>1</td>\n",
       "      <td>1387</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22336</th>\n",
       "      <td>29996</td>\n",
       "      <td>Apple iPhone 5c 32GB (Blue) - AT&amp;T</td>\n",
       "      <td>Apple</td>\n",
       "      <td>274.95</td>\n",
       "      <td>5</td>\n",
       "      <td>The phone was just like described . Not a sing...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[phone, like, described, ., single, scratch, s...</td>\n",
       "      <td>phonelikedescribed singlescratchscreenshippedw...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22337</th>\n",
       "      <td>29997</td>\n",
       "      <td>Apple iPhone 5c 32GB (Blue) - AT&amp;T</td>\n",
       "      <td>Apple</td>\n",
       "      <td>274.95</td>\n",
       "      <td>2</td>\n",
       "      <td>Gave 3 stars because it did not come with a ch...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[gave, 3, stars, come, charger, box., battery,...</td>\n",
       "      <td>gave starcomechargerbox batteryalreadyhalfwayg...</td>\n",
       "      <td>1</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22338</th>\n",
       "      <td>29998</td>\n",
       "      <td>Apple iPhone 5c 32GB (Blue) - AT&amp;T</td>\n",
       "      <td>Apple</td>\n",
       "      <td>274.95</td>\n",
       "      <td>5</td>\n",
       "      <td>phone looks new! Works great!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[phone, looks, new!, works, great!]</td>\n",
       "      <td>phonelooknew workgreat</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22339</th>\n",
       "      <td>29999</td>\n",
       "      <td>Apple iPhone 5c 32GB (Blue) - AT&amp;T</td>\n",
       "      <td>Apple</td>\n",
       "      <td>274.95</td>\n",
       "      <td>4</td>\n",
       "      <td>This phone was just as I was wishing for, but ...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[phone, wishing, for,, one, slight, problem, (...</td>\n",
       "      <td>phonewishingfor oneslightproblem worry  simcar...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22340 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                       Product Name Brand Name  \\\n",
       "0          0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung   \n",
       "1          1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung   \n",
       "2          2  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung   \n",
       "3          3  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung   \n",
       "4          4  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung   \n",
       "...      ...                                                ...        ...   \n",
       "22335  29995                 Apple iPhone 5c 32GB (Blue) - AT&T      Apple   \n",
       "22336  29996                 Apple iPhone 5c 32GB (Blue) - AT&T      Apple   \n",
       "22337  29997                 Apple iPhone 5c 32GB (Blue) - AT&T      Apple   \n",
       "22338  29998                 Apple iPhone 5c 32GB (Blue) - AT&T      Apple   \n",
       "22339  29999                 Apple iPhone 5c 32GB (Blue) - AT&T      Apple   \n",
       "\n",
       "        Price  Rating                                            Reviews  \\\n",
       "0      199.99       5  I feel so LUCKY to have found this used (phone...   \n",
       "1      199.99       4  nice phone, nice up grade from my pantach revu...   \n",
       "2      199.99       5                                       Very pleased   \n",
       "3      199.99       4  It works good but it goes slow sometimes but i...   \n",
       "4      199.99       4  Great phone to replace my lost phone. The only...   \n",
       "...       ...     ...                                                ...   \n",
       "22335  274.95       5  The description said it was in 'very good' con...   \n",
       "22336  274.95       5  The phone was just like described . Not a sing...   \n",
       "22337  274.95       2  Gave 3 stars because it did not come with a ch...   \n",
       "22338  274.95       5                      phone looks new! Works great!   \n",
       "22339  274.95       4  This phone was just as I was wishing for, but ...   \n",
       "\n",
       "       Review Votes                                         NewReviews  \\\n",
       "0               1.0  [feel, lucky, found, used, (phone, us, &, used...   \n",
       "1               0.0  [nice, phone,, nice, grade, pantach, revue., c...   \n",
       "2               0.0                                          [pleased]   \n",
       "3               0.0  [works, good, goes, slow, sometimes, good, pho...   \n",
       "4               0.0  [great, phone, replace, lost, phone., thing, v...   \n",
       "...             ...                                                ...   \n",
       "22335           0.0  [description, said, 'very, good', condition,, ...   \n",
       "22336           0.0  [phone, like, described, ., single, scratch, s...   \n",
       "22337           0.0  [gave, 3, stars, come, charger, box., battery,...   \n",
       "22338           0.0                [phone, looks, new!, works, great!]   \n",
       "22339           9.0  [phone, wishing, for,, one, slight, problem, (...   \n",
       "\n",
       "                                         Cleaned_reviews  KMEANS  DBSCAN  \\\n",
       "0      feelluckyfoundused phoneu usedhardall  phoneli...       1       0   \n",
       "1      nicephone nicegradepantachrevue cleanseteasyse...       1       1   \n",
       "2                                                pleased       1       2   \n",
       "3                   workgoodgoslowsometimesgoodphonelove       1       0   \n",
       "4      greatphonereplacelostphone thingvolumebuttonwo...       1       0   \n",
       "...                                                  ...     ...     ...   \n",
       "22335  descriptionsaid verygood condition actuallyrec...       1    1387   \n",
       "22336  phonelikedescribed singlescratchscreenshippedw...       1       0   \n",
       "22337  gave starcomechargerbox batteryalreadyhalfwayg...       1     234   \n",
       "22338                             phonelooknew workgreat       4      57   \n",
       "22339  phonewishingfor oneslightproblem worry  simcar...       1       0   \n",
       "\n",
       "       Hierarchical clustering  \n",
       "0                            0  \n",
       "1                            0  \n",
       "2                            0  \n",
       "3                            0  \n",
       "4                            0  \n",
       "...                        ...  \n",
       "22335                        0  \n",
       "22336                        0  \n",
       "22337                        0  \n",
       "22338                        0  \n",
       "22339                        0  \n",
       "\n",
       "[22340 rows x 12 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cluster_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "In_class_exercise_05-1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
